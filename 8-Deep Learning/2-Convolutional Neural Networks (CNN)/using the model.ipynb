{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19d8bd19-74a6-4ff0-bcd7-07ed2c3ccddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sahil\\AppData\\Roaming\\Python\\Python311\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sahil\\AppData\\Roaming\\Python\\Python311\\site-packages\\tf_keras\\src\\saving\\legacy\\saved_model\\load.py:109: The name tf.gfile.Exists is deprecated. Please use tf.io.gfile.exists instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sahil\\AppData\\Roaming\\Python\\Python311\\site-packages\\tf_keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sahil\\AppData\\Roaming\\Python\\Python311\\site-packages\\tf_keras\\src\\utils\\tf_utils.py:585: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Load the model\n",
    "cnn = tf.keras.models.load_model('my_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a67b767-86c1-4866-a967-8676efa4473a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 8s 8s/step\n",
      "[[1.]]\n",
      "dog\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "[[1.]]\n",
      "dog\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "[[0.]]\n",
      "cat\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "[[1.]]\n",
      "dog\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "for i in range(1,5):\n",
    "    test_image = image.load_img(f\"dataset/single_prediction/cat_or_dog_{i}.jpg\", target_size = (64, 64))\n",
    "    test_image = image.img_to_array(test_image)\n",
    "    test_image = np.expand_dims(test_image, axis = 0)\n",
    "    result = cnn.predict(test_image)\n",
    "    print(result)\n",
    "    if result[0][0] == 1:\n",
    "        prediction = 'dog'\n",
    "    else:\n",
    "        prediction = 'cat'\n",
    "    print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f847c82c-3e0d-44e3-997c-94d5996093e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "cnn = tf.keras.models.load_model('cat_or_dog_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b72437ec-6469-4514-9d9a-270af23b6409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 384ms/step\n",
      "[[1.]]\n",
      "dog\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "[[1.]]\n",
      "dog\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "[[0.]]\n",
      "cat\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "[[1.]]\n",
      "dog\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "for i in range(1,5):\n",
    "    test_image = image.load_img(f\"dataset/single_prediction/cat_or_dog_{i}.jpg\", target_size = (64, 64))\n",
    "    test_image = image.img_to_array(test_image)\n",
    "    test_image = np.expand_dims(test_image, axis = 0)\n",
    "    result = cnn.predict(test_image)\n",
    "    print(result)\n",
    "    if result[0][0] == 1:\n",
    "        prediction = 'dog'\n",
    "    else:\n",
    "        prediction = 'cat'\n",
    "    print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dcb19934-8bec-4c63-bfb7-440ba3b1ceeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4152: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 59\u001b[0m\n\u001b[0;32m     56\u001b[0m cropped_frame \u001b[38;5;241m=\u001b[39m frame[startY:endY, startX:endX]\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# Classify the cropped region using the CNN model\u001b[39;00m\n\u001b[1;32m---> 59\u001b[0m predicted_class_label \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcropped_frame\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# Draw bounding box and label on the frame\u001b[39;00m\n\u001b[0;32m     62\u001b[0m label \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpredicted_class_label\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfidence\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "Cell \u001b[1;32mIn[5], line 19\u001b[0m, in \u001b[0;36mpredict_frame\u001b[1;34m(model, frame)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_frame\u001b[39m(model, frame):\n\u001b[1;32m---> 19\u001b[0m     preprocessed_frame \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(preprocessed_frame)\n\u001b[0;32m     21\u001b[0m     predicted_class_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(np\u001b[38;5;241m.\u001b[39mround(prediction[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]))  \u001b[38;5;66;03m# Assuming binary classification with sigmoid activation\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[5], line 13\u001b[0m, in \u001b[0;36mpreprocess_frame\u001b[1;34m(frame, img_size)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreprocess_frame\u001b[39m(frame, img_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m64\u001b[39m)):\n\u001b[1;32m---> 13\u001b[0m     img_array \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m     img_array \u001b[38;5;241m=\u001b[39m img_array\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255.0\u001b[39m\n\u001b[0;32m     15\u001b[0m     img_array \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(img_array, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# Add batch dimension\u001b[39;00m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4152: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Assuming your trained model is stored in the variable `cnn`\n",
    "model = cnn\n",
    "\n",
    "# Define class indices (this should match how you defined them during training)\n",
    "class_indices = {'cat': 0, 'dog': 1}\n",
    "index_to_class = {v: k for k, v in class_indices.items()}\n",
    "\n",
    "def preprocess_frame(frame, img_size=(64, 64)):\n",
    "    img_array = cv2.resize(frame, img_size)\n",
    "    img_array = img_array.astype('float32') / 255.0\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
    "    return img_array\n",
    "\n",
    "def predict_frame(model, frame):\n",
    "    preprocessed_frame = preprocess_frame(frame)\n",
    "    prediction = model.predict(preprocessed_frame)\n",
    "    predicted_class_index = int(np.round(prediction[0][0]))  # Assuming binary classification with sigmoid activation\n",
    "    predicted_class_label = index_to_class[predicted_class_index]\n",
    "    return predicted_class_label\n",
    "\n",
    "# Load the pre-trained MobileNet SSD model for object detection\n",
    "prototxt_path = 'deploy.prototxt'\n",
    "caffemodel_path = 'mobilenet_iter_73000.caffemodel'\n",
    "net = cv2.dnn.readNetFromCaffe(prototxt_path, caffemodel_path)\n",
    "\n",
    "# Start video capture from camera\n",
    "cap = cv2.VideoCapture(0)  # Use 0 for the default camera\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Prepare the frame for object detection\n",
    "    (h, w) = frame.shape[:2]\n",
    "    blob = cv2.dnn.blobFromImage(cv2.resize(frame, (300, 300)), 0.007843, (300, 300), 127.5)\n",
    "    net.setInput(blob)\n",
    "    detections = net.forward()\n",
    "\n",
    "    for i in range(detections.shape[2]):\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "        if confidence > 0.2:  # Confidence threshold\n",
    "            # Extract the index of the class label from the detections\n",
    "            idx = int(detections[0, 0, i, 1])\n",
    "\n",
    "            # If the detected object is a dog or cat\n",
    "            if idx in [15, 3]:  # Adjust this based on the object detector's class labels for 'dog' and 'cat'\n",
    "                box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "                (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "\n",
    "                # Crop the detected region\n",
    "                cropped_frame = frame[startY:endY, startX:endX]\n",
    "\n",
    "                # Classify the cropped region using the CNN model\n",
    "                predicted_class_label = predict_frame(model, cropped_frame)\n",
    "\n",
    "                # Draw bounding box and label on the frame\n",
    "                label = f\"{predicted_class_label}: {confidence:.2f}\"\n",
    "                cv2.rectangle(frame, (startX, startY), (endX, endY), (0, 255, 0), 2)\n",
    "                y = startY - 15 if startY - 15 > 15 else startY + 15\n",
    "                cv2.putText(frame, label, (startX, y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "    # Display the output frame\n",
    "    cv2.imshow('Live Dog/Cat Classifier', frame)\n",
    "\n",
    "    # Break loop on 'q' key press\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the capture and close windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbf2e39-3aab-4666-8acc-db9b8b18d9e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
